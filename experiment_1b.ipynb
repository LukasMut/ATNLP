{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.408136Z",
     "start_time": "2019-12-08T15:17:19.876618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import matplotlib\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models.Encoder import *\n",
    "from models.Decoder import *\n",
    "from models.utils import *\n",
    "from utils import *\n",
    "\n",
    "# set fixed random seed to reproduce results\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.414602Z",
     "start_time": "2019-12-08T15:17:22.408136Z"
    }
   },
   "outputs": [],
   "source": [
    "# define experiment\n",
    "exp='/exp_1'\n",
    "# define number of iterations\n",
    "n_iters = 20000\n",
    "# define batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.421587Z",
     "start_time": "2019-12-08T15:17:22.416609Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.582872Z",
     "start_time": "2019-12-08T15:17:22.422592Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset into memory, and get w2idx, idx2w, w2freq dictionaries and lists of input and output sentences\n",
    "cmd_vocab, w2i_cmds, i2w_cmds, cmds_train, act_vocab, w2i_acts, i2w_acts, acts_train = load_dataset(exp=exp, split='/train')\n",
    "_, _, _, cmds_test, _, _, _, acts_test = load_dataset(exp=exp, split='/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.594505Z",
     "start_time": "2019-12-08T15:17:22.582872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train source-target pairs: 16728\n",
      "Number of test source-target pairs: 4182\n"
     ]
    }
   ],
   "source": [
    "## create input and output language pairs ##\n",
    "\n",
    "# training\n",
    "train_cmd_act_pairs = create_pairs(cmds_train, acts_train)\n",
    "print(\"Number of train source-target pairs: {}\".format(len(train_cmd_act_pairs)))\n",
    "\n",
    "# testing\n",
    "test_cmd_act_pairs = create_pairs(cmds_test, acts_test)\n",
    "print(\"Number of test source-target pairs: {}\".format(len(test_cmd_act_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.602586Z",
     "start_time": "2019-12-08T15:17:22.594505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['look', 'left', 'thrice', 'after', 'turn', 'opposite', 'left']\n",
      "Action: ['I_TURN_LEFT', 'I_TURN_LEFT', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK']\n"
     ]
    }
   ],
   "source": [
    "# show random train command-action pair\n",
    "random_pair = random.choice(train_cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:22.610421Z",
     "start_time": "2019-12-08T15:17:22.602586Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['run', 'right', 'thrice', 'after', 'jump', 'right']\n",
      "Action: ['I_TURN_RIGHT', 'I_JUMP', 'I_TURN_RIGHT', 'I_RUN', 'I_TURN_RIGHT', 'I_RUN', 'I_TURN_RIGHT', 'I_RUN']\n"
     ]
    }
   ],
   "source": [
    "# show random test command-action pair\n",
    "random_pair = random.choice(test_cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:37.134797Z",
     "start_time": "2019-12-08T15:17:22.610421Z"
    }
   },
   "outputs": [],
   "source": [
    "cmds_train, acts_train, input_lengths_train, masks = pairs2idx(cmds_train, acts_train, w2i_cmds, w2i_acts, padding=True, training=True)\n",
    "cmds_test, acts_test, input_lengths_test = pairs2idx(cmds_test, acts_test, w2i_cmds, w2i_acts, padding=True, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:37.143110Z",
     "start_time": "2019-12-08T15:17:37.134797Z"
    }
   },
   "outputs": [],
   "source": [
    "# create train and test data loaders\n",
    "train_dl = create_batches(cmds_train, acts_train, input_lengths_train, batch_size=batch_size, masks=masks, split='train', num_samples=n_iters)\n",
    "test_dl = create_batches(cmds_test, acts_test, input_lengths_test, batch_size=batch_size, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:37.150091Z",
     "start_time": "2019-12-08T15:17:37.144081Z"
    }
   },
   "outputs": [],
   "source": [
    "### Hyperparameters for training ###\n",
    "\n",
    "# source language (i.e., commands) vocabulary size |V_source|\n",
    "in_size = len(w2i_cmds)\n",
    "\n",
    "# target language (i.e., actions) vocabulary size |V_target|\n",
    "out_size = len(w2i_acts)\n",
    "\n",
    "# size of word embeddings\n",
    "emb_size = 20\n",
    "\n",
    "# size of hidden units\n",
    "hidden_size = 100\n",
    "\n",
    "# number of layers\n",
    "n_layers = 2\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "# layer dropout rate\n",
    "dropout_p = 0.3\n",
    "\n",
    "# define whether encoder is uni- or bidirectional\n",
    "bidir = False\n",
    "\n",
    "# number of epochs\n",
    "n_epochs = 8 # 7-10 epochs (20.000 iterations each) seem to be sufficient to learn the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:37.173498Z",
     "start_time": "2019-12-08T15:17:37.150617Z"
    }
   },
   "outputs": [],
   "source": [
    "## Instantiate models ##\n",
    "\n",
    "encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers, dropout=dropout_p, bidir=bidir)\n",
    "decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers, dropout=dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:37.189115Z",
     "start_time": "2019-12-08T15:17:37.173498Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoder = EncoderGRU(in_size, emb_size, hidden_size, n_layers, dropout=dropout_p, bidir=True)\n",
    "#decoder = DecoderGRU(emb_size, hidden_size, out_size, n_layers, dropout=dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:38.740634Z",
     "start_time": "2019-12-08T15:17:37.189115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderLSTM(\n",
       "  (embedding): Embedding(16, 20, padding_idx=0)\n",
       "  (lstm): LSTM(20, 100, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:17:38.748669Z",
     "start_time": "2019-12-08T15:17:38.741631Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(9, 20, padding_idx=0)\n",
       "  (lstm): LSTM(20, 100, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (linear): Linear(in_features=100, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move models to GPU, if GPU is available (for faster computation)\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:20:30.532714Z",
     "start_time": "2019-12-08T15:17:38.749666Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: nan\n",
      "Acc: 0.00031146179401993354\n",
      "\n",
      "Command: run opposite right twice after walk opposite right twice <EOS>\n",
      "True action: I_TURN_RIGHT I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_RUN I_TURN_RIGHT I_TURN_RIGHT I_RUN <EOS>\n",
      "Pred action: I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_WALK I_TURN_RIGHT I_TURN_RIGHT I_RUN I_RUN <EOS>\n",
      "\n",
      "True sent length: 13\n",
      "Pred sent length: 13\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1509ad1ee3fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                                    learning_rate=lr)\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\ATNLP\\models\\utils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_dl, w2i_source, w2i_target, i2w_source, i2w_target, encoder, decoder, epochs, batch_size, learning_rate, max_ratio, min_ratio, detailed_analysis)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m#SOS_token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;31m# Teacher forcing: feed target as the next input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ATNLP\\models\\Decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_batch, hidden)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mprobas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprobas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, encoder, decoder = train(train_dl,\n",
    "                                                   w2i_cmds, w2i_acts,\n",
    "                                                   i2w_cmds, i2w_acts,\n",
    "                                                   encoder, decoder,\n",
    "                                                   epochs=n_epochs,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:20:30.541689Z",
     "start_time": "2019-12-08T15:17:19.938Z"
    }
   },
   "outputs": [],
   "source": [
    "test_acc = test(test_dl,\n",
    "                w2i_cmds, w2i_acts, \n",
    "                i2w_cmds, i2w_acts, \n",
    "                encoder, decoder,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test over different numbers of distinct source-target pairs (1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:20:30.543688Z",
     "start_time": "2019-12-08T15:17:19.949Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## experiment 1b train and test loop over pre-defined ratios ##\n",
    "\n",
    "ratios = np.array([0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64])\n",
    "accs_per_ratio = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    train_samples = sample_distinct_pairs(train_cmd_act_pairs, ratio)\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Current percentage of total commands used for training: {}%\".format(ratio*100))\n",
    "    print(\"Number of distinct examples shown during training: {}\".format(len(train_samples)))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    # instantiate new encoder and decoder for each ratio\n",
    "    encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "    decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    train_losses, train_accs, encoder, decoder = train(train_samples, w2i_cmds, w2i_acts, i2w_cmds, i2w_acts, encoder, decoder, n_epochs)\n",
    "    test_acc = test(test_cmd_act_pairs, w2i_cmds, w2i_acts, i2w_cmds, i2w_acts, encoder, decoder)\n",
    "    accs_per_ratio[ratio] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:20:30.544681Z",
     "start_time": "2019-12-08T15:17:19.950Z"
    }
   },
   "outputs": [],
   "source": [
    "# save results in .json file\n",
    "with open('./results/experiment_1b.json', 'w') as json_file:\n",
    "      json.dump(accs_per_ratio, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:20:30.545678Z",
     "start_time": "2019-12-08T15:17:19.951Z"
    }
   },
   "outputs": [],
   "source": [
    "# load results from experiment 1b\n",
    "with open('./results/experiment_1b.json') as json_file:\n",
    "    accs_per_ratio = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T15:20:30.546686Z",
     "start_time": "2019-12-08T15:17:19.952Z"
    }
   },
   "outputs": [],
   "source": [
    "ratios, test_accs = zip(*accs_per_ratio.items())\n",
    "plt.bar(ratios, test_accs)\n",
    "plt.xlabel('Percent of distinct commands used for training')\n",
    "plt.ylabel('Test accuracy on unseen commands (%)')\n",
    "plt.xticks(ticks=ratios, labels=list(map(lambda rat: str(int(float(rat) * 100)) + '%', ratios)))\n",
    "plt.title('Experiment 1b')\n",
    "plt.savefig('./Paper/Plots/experiment_1b.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
