{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.703294Z",
     "start_time": "2019-12-04T15:00:29.115498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import matplotlib\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models.Encoder import *\n",
    "from models.Decoder import *\n",
    "from models.utils import *\n",
    "from utils import *\n",
    "\n",
    "# set fixed random seed to reproduce results\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.708136Z",
     "start_time": "2019-12-04T15:00:31.703294Z"
    }
   },
   "outputs": [],
   "source": [
    "# define experiment\n",
    "exp='/exp_1'\n",
    "# define number of iterations\n",
    "n_iters = 20000\n",
    "# define batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.713145Z",
     "start_time": "2019-12-04T15:00:31.709134Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.953481Z",
     "start_time": "2019-12-04T15:00:31.716115Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset into memory, and get w2idx, idx2w, w2freq dictionaries and lists of input and output sentences\n",
    "cmd_vocab, w2i_cmds, i2w_cmds, cmds_train, act_vocab, w2i_acts, i2w_acts, acts_train = load_dataset(exp=exp, split='/train')\n",
    "_, _, _, cmds_test, _, _, _, acts_test = load_dataset(exp=exp, split='/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.971432Z",
     "start_time": "2019-12-04T15:00:31.954478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train source-target pairs: 16728\n",
      "Number of test source-target pairs: 4182\n"
     ]
    }
   ],
   "source": [
    "## create input and output language pairs ##\n",
    "\n",
    "# training\n",
    "train_cmd_act_pairs = create_pairs(cmds_train, acts_train)\n",
    "print(\"Number of train source-target pairs: {}\".format(len(train_cmd_act_pairs)))\n",
    "\n",
    "# testing\n",
    "test_cmd_act_pairs = create_pairs(cmds_test, acts_test)\n",
    "print(\"Number of test source-target pairs: {}\".format(len(test_cmd_act_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.981405Z",
     "start_time": "2019-12-04T15:00:31.973427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['look', 'left', 'thrice', 'after', 'turn', 'opposite', 'left']\n",
      "Action: ['I_TURN_LEFT', 'I_TURN_LEFT', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK']\n"
     ]
    }
   ],
   "source": [
    "# show random train command-action pair\n",
    "random_pair = random.choice(train_cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:31.992376Z",
     "start_time": "2019-12-04T15:00:31.984397Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['run', 'right', 'thrice', 'after', 'jump', 'right']\n",
      "Action: ['I_TURN_RIGHT', 'I_JUMP', 'I_TURN_RIGHT', 'I_RUN', 'I_TURN_RIGHT', 'I_RUN', 'I_TURN_RIGHT', 'I_RUN']\n"
     ]
    }
   ],
   "source": [
    "# show random test command-action pair\n",
    "random_pair = random.choice(test_cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:48.739909Z",
     "start_time": "2019-12-04T15:00:48.735884Z"
    }
   },
   "outputs": [],
   "source": [
    "## Hyperparameters for training ##\n",
    "\n",
    "# source language (i.e., commands) vocabulary size |V_source|\n",
    "in_size = len(w2i_cmds)\n",
    "\n",
    "# target language (i.e., actions) vocabulary size |V_target|\n",
    "out_size = len(w2i_acts)\n",
    "\n",
    "# size of word embeddings\n",
    "emb_size = 20\n",
    "\n",
    "# size of hidden units\n",
    "hidden_size = 100\n",
    "\n",
    "# number of layers\n",
    "n_layers = 2\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "# number of epochs\n",
    "n_epochs = 8 # 5-10 epochs (20.000 iterations each) seem to be sufficient to learn the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:48.761046Z",
     "start_time": "2019-12-04T15:00:48.740870Z"
    }
   },
   "outputs": [],
   "source": [
    "## Instantiate models ##\n",
    "\n",
    "encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:00:50.290935Z",
     "start_time": "2019-12-04T15:00:48.761046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(9, 20)\n",
       "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (lstm): LSTM(20, 100, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=100, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move models to GPU, if GPU is available (for faster computation)\n",
    "encoder.cuda()\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T16:05:23.780489Z",
     "start_time": "2019-12-04T16:05:23.777503Z"
    }
   },
   "outputs": [],
   "source": [
    "train_losses, train_accs, encoder, decoder = train(train_cmd_act_pairs,\n",
    "                                                   w2i_cmds, w2i_acts,\n",
    "                                                   i2w_cmds, i2w_acts,\n",
    "                                                   encoder, decoder,\n",
    "                                                   epochs=n_epochs,\n",
    "                                                   n_iters=n_iters,\n",
    "                                                   learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:05:42.959256Z",
     "start_time": "2019-12-04T15:00:29.253Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_acc = test(test_dl, w2i_cmds, w2i_acts, i2w_cmds, i2w_acts, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test over different numbers of distinct source-target pairs (1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:05:42.960253Z",
     "start_time": "2019-12-04T15:00:29.275Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## experiment 1b train and test loop over pre-defined ratios ##\n",
    "\n",
    "ratios = np.array([0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64])\n",
    "accs_per_ratio = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    train_samples = sample_distinct_pairs(train_cmd_act_pairs, ratio)\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Current percentage of total commands used for training: {}%\".format(ratio*100))\n",
    "    print(\"Number of distinct examples shown during training: {}\".format(len(train_samples)))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    # instantiate new encoder and decoder for each ratio\n",
    "    encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "    decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    train_losses, train_accs, encoder, decoder = train(train_samples,\n",
    "                                                       w2i_cmds, w2i_acts,\n",
    "                                                       i2w_cmds, i2w_acts,\n",
    "                                                       encoder, decoder,\n",
    "                                                       epochs=n_epochs,\n",
    "                                                       n_iters=n_iters,\n",
    "                                                       learning_rate=lr)\n",
    "    test_acc = test(test_cmd_act_pairs, w2i_cmds, w2i_acts, i2w_cmds, i2w_acts, encoder, decoder)\n",
    "    accs_per_ratio[ratio] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:05:42.961249Z",
     "start_time": "2019-12-04T15:00:29.278Z"
    }
   },
   "outputs": [],
   "source": [
    "# save results in .json file\n",
    "with open('./results/experiment_1b.json', 'w') as json_file:\n",
    "      json.dump(accs_per_ratio, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:05:42.962246Z",
     "start_time": "2019-12-04T15:00:29.281Z"
    }
   },
   "outputs": [],
   "source": [
    "# load results from experiment 1b\n",
    "with open('./results/experiment_1b.json') as json_file:\n",
    "    accs_per_ratio = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T15:05:42.963244Z",
     "start_time": "2019-12-04T15:00:29.286Z"
    }
   },
   "outputs": [],
   "source": [
    "ratios, test_accs = zip(*accs_per_ratio.items())\n",
    "plt.bar(ratios, test_accs)\n",
    "plt.xlabel('Percent of distinct commands used for training')\n",
    "plt.ylabel('Test accuracy on unseen commands (%)')\n",
    "plt.xticks(ticks=ratios, labels=list(map(lambda rat: str(int(float(rat) * 100)) + '%', ratios)))\n",
    "plt.title('Experiment 1b')\n",
    "plt.savefig('./Paper/Plots/experiment_1b.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
