{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lang_pairs, w2i_source, w2i_target, i2w_source, i2w_target, encoder, decoder, epochs:int, batch_size:int=1,\n",
    "          learning_rate:float=1e-3, max_ratio:float=0.95, min_ratio:float=0.15, detailed_analysis:bool=True):\n",
    "        \n",
    "    # each n_iters plot behaviour of RNN Decoder\n",
    "    n_iters = 3000\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    #training_pairs = [pairs2idx(random.choice(lang_pairs), w2i_cmds, w2i_acts) for _ in range(len(lang_pairs))]\n",
    "    training_pairs = lang_pairs\n",
    "    max_target_length = max(iter(map(lambda lang_pair: len(lang_pair[1]), training_pairs)))\n",
    "    n_lang_pairs = len(training_pairs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # negative log-likelihood loss\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # teacher forcing curriculum\n",
    "    # decrease teacher forcing ratio per epoch (start off with high ratio and move in equal steps to min_ratio)\n",
    "    ratio_diff = max_ratio-min_ratio\n",
    "    step_per_epoch = ratio_diff / epochs\n",
    "    teacher_forcing_ratio = max_ratio\n",
    "    \n",
    "    for epoch in trange(epochs,  desc=\"Epoch\"):\n",
    "                \n",
    "        loss_per_epoch = 0\n",
    "        acc_per_epoch = 0\n",
    "        np.random.shuffle(training_pairs)\n",
    "        \n",
    "        \n",
    "        #create batch iterator\n",
    "        batch_iterator = create_batches(training_pairs, batch_size)\n",
    "\n",
    "        for mini_batch in batch_iterator:\n",
    "        \n",
    "            commands_batch, actions_batch, inp_lengths, mask, max_target_length = prepare_batch(mini_batch)\n",
    "            \n",
    "            \n",
    "            # initialise as many hidden states as there are sequences in the mini-batch (1 for the beginning)\n",
    "            encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            loss = 0\n",
    "            \n",
    "            #print(commands_batch)\n",
    "\n",
    "            commands_batch = commands_batch.to(device)\n",
    "            actions_batch = actions_batch.to(device)\n",
    "            inp_lengths = inp_lengths.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "\n",
    "            #input_length = command.size(0)\n",
    "            #target_length = action.size(0)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(commands_batch, inp_lengths, encoder_hidden)\n",
    "\n",
    "            decoder_input = torch.LongTensor([[1 for _ in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "\n",
    "            # Set initial decoder hidden state to the encoder's final hidden state\n",
    "            decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "            pred_sent = \"\"\n",
    "            true_sent = ' '.join([i2w_target[act.item()] for act in islice(action, 1, None)]).strip() # skip SOS token\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: feed target as the next input\n",
    "                for i in range(1, max_target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0  # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "\n",
    "                    #loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    \n",
    "                    # Teacher forcing: next input is current target\n",
    "                    decoder_input = target_variable[i].view(1, -1)\n",
    "                    # Calculate and accumulate loss\n",
    "                    mask_loss, nTotal = maskNLLLoss(decoder_output, actions_batch[i], mask[i])\n",
    "                    loss += mask_loss\n",
    "                    print_losses.append(mask_loss.item() * nTotal)\n",
    "                    n_totals += nTotal\n",
    "                    #decoder_input = acts_batch[i] # convert list of int into int\n",
    "\n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "\n",
    "                    #if pred.squeeze().item() == w2i_target['<EOS>']:\n",
    "                    #    break\n",
    "            else:\n",
    "                # Autoregressive RNN: feed previous prediction as the next input\n",
    "                for i in range(1, max_target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0 # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "\n",
    "                    # No teacher forcing: next input is decoder's own current output\n",
    "                    _, topi = decoder_output.topk(1)\n",
    "                    decoder_input = torch.LongTensor([[topi[j][0] for j in range(batch_size)]])\n",
    "                    decoder_input = decoder_input.to(device)\n",
    "                    # Calculate and accumulate loss\n",
    "                    mask_loss, nTotal = maskNLLLoss(decoder_output, actions_batch[i], mask[i])\n",
    "                    loss += mask_loss\n",
    "                    print_losses.append(mask_loss.item() * nTotal)\n",
    "                    n_totals += nTotal\n",
    "\n",
    "                    decoder_input = pred.squeeze() # convert list of int into int\n",
    "\n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "\n",
    "                    #if decoder_input.item() == w2i_target['<EOS>']:\n",
    "                    #    break\n",
    "\n",
    "            # strip off any leading or trailing white spaces\n",
    "            pred_sent = pred_sent.strip()\n",
    "            acc_per_epoch += 1 if pred_sent == true_sent else 0 # exact match accuracy\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "        ### Inspect translation behaviour ###\n",
    "        if detailed_analysis:\n",
    "            nl_command = ' '.join([i2w_source[cmd.item()] for cmd in command]).strip()\n",
    "            if idx > 0 and idx % n_iters == 0:\n",
    "                print(\"Loss: {}\".format(loss.item() / target_length)) # current per sequence loss\n",
    "                print(\"Acc: {}\".format(acc_per_epoch / (idx + 1))) # current per iters exact-match accuracy\n",
    "                print()\n",
    "                print(\"Command: {}\".format(nl_command))\n",
    "                print(\"True action: {}\".format(true_sent))\n",
    "                print(\"Pred action: {}\".format(pred_sent))\n",
    "                print()\n",
    "                print(\"True sent length: {}\".format(len(true_sent.split())))\n",
    "                print(\"Pred sent length: {}\".format(len(pred_sent.split())))\n",
    "                print()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        loss_per_epoch += loss.item() / target_length\n",
    "\n",
    "        loss_per_epoch /= n_lang_pairs\n",
    "        acc_per_epoch /= n_lang_pairs\n",
    "        \n",
    "        print(\"Train loss: {}\".format(loss_per_epoch)) # loss\n",
    "        print(\"Train acc: {}\".format(acc_per_epoch)) # exact-match accuracy\n",
    "        print(\"Current teacher forcing ratio {}\".format(teacher_forcing_ratio))\n",
    "        \n",
    "        train_losses.append(loss_per_epoch)\n",
    "        train_accs.append(acc_per_epoch)\n",
    "        \n",
    "        teacher_forcing_ratio -= step_per_epoch # decrease teacher forcing ratio\n",
    "        \n",
    "    return train_losses, train_accs"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
