{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.549944Z",
     "start_time": "2019-11-27T13:58:36.153305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from itertools import islice\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models.Encoder import *\n",
    "from models.Decoder import *\n",
    "from utils import *\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.555026Z",
     "start_time": "2019-11-27T13:58:37.549944Z"
    }
   },
   "outputs": [],
   "source": [
    "# define experiment\n",
    "exp='/exp_1a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.565027Z",
     "start_time": "2019-11-27T13:58:37.557020Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.691707Z",
     "start_time": "2019-11-27T13:58:37.566030Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset into memory, and get w2idx, idx2w, w2freq dictionaries and lists of input and output sentences\n",
    "cmd_vocab, w2i_cmds, i2w_cmds, cmds, act_vocab, w2i_acts, i2w_acts, acts = load_dataset(exp=exp, split='/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.699639Z",
     "start_time": "2019-11-27T13:58:37.692657Z"
    }
   },
   "outputs": [],
   "source": [
    "# create input and output language pairs\n",
    "cmd_act_pairs = create_pairs(cmds, acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.706652Z",
     "start_time": "2019-11-27T13:58:37.700647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['look', 'left', 'thrice', 'after', 'turn', 'opposite', 'left']\n",
      "Action: ['I_TURN_LEFT', 'I_TURN_LEFT', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK']\n"
     ]
    }
   ],
   "source": [
    "# show random command-action pair\n",
    "random_pair = random.choice(cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.713621Z",
     "start_time": "2019-11-27T13:58:37.707618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command sequence: tensor([13,  5,  7, 10, 16,  8,  5,  2])\n",
      "Action sequence: tensor([1, 5, 5, 5, 9, 5, 9, 5, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "cmd_act_pair = pairs2idx(random_pair, w2i_cmds, w2i_acts)\n",
    "print(\"Command sequence: {}\".format(cmd_act_pair[0]))\n",
    "print(\"Action sequence: {}\".format(cmd_act_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:01:41.340761Z",
     "start_time": "2019-11-27T14:01:41.321512Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(lang_pairs, w2i_source, w2i_target, i2w_target, encoder, decoder, epochs:int,\n",
    "          batch_size:int=1, learning_rate:float=1e-3, max_ratio:float=0.95, min_ratio:float=0.15):\n",
    "        \n",
    "    train_losses, train_accs = [], []\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    training_pairs = [pairs2idx(random.choice(lang_pairs), w2i_cmds, w2i_acts) for _ in range(len(lang_pairs))]\n",
    "    max_target_length = max(iter(map(lambda lang_pair: len(lang_pair[1]), training_pairs)))\n",
    "    n_lang_pairs = len(training_pairs)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # decrease teacher forcing ratio per epoch (start off with high ratio and move in equal steps to min_ratio)\n",
    "    ratio_diff = max_ratio-min_ratio\n",
    "    step_per_epoch = ratio_diff / epochs\n",
    "    teacher_forcing_ratio = max_ratio\n",
    "    \n",
    "    for epoch in trange(epochs,  desc=\"Epoch\"):\n",
    "                \n",
    "        loss_per_epoch = 0\n",
    "        acc_per_epoch = 0\n",
    "        \n",
    "        for idx, train_pair in enumerate(training_pairs):\n",
    "            \n",
    "            loss = 0\n",
    "            \n",
    "            command = train_pair[0].to(device)\n",
    "            action = train_pair[1].to(device)\n",
    "            \n",
    "            # initialise as many hidden states as there are sequences in the mini-batch (1 for the beginning)\n",
    "            encoder_hidden = encoder.init_hidden(batch_size)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            input_length = command.size(0)\n",
    "            target_length = action.size(0)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(command, encoder_hidden)\n",
    "            \n",
    "            decoder_input = action[0] # SOS token\n",
    "            \n",
    "            decoder_hidden = encoder_hidden # init decoder hidden with encoder hidden \n",
    "\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            \n",
    "            pred_sent = \"\"\n",
    "            true_sent = ' '.join([i2w_target[act.item()] for act in islice(action, 1, None)]) # skip SOS token\n",
    "            \n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: feed target as the next input\n",
    "                for i in range(1, target_length): # range(1, max_target_length)\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0  # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    decoder_input = action[i] # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                \n",
    "            else:\n",
    "                # Autoregression: feed previous prediction as the next input\n",
    "                for i in range(1, max_target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0 # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    if i >= target_length:\n",
    "                        loss += criterion(decoder_out, torch.tensor(w2i_target['<EOS>'], dtype=torch.long).unsqueeze(0).to(device))\n",
    "                    else:\n",
    "                        loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    \n",
    "                    decoder_input = pred.squeeze() # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if decoder_input.item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "\n",
    "            acc_per_epoch += 1 if (pred_sent == true_sent) else 0 # exact match accuracy\n",
    "        \n",
    "            loss.backward()\n",
    "            \n",
    "            # inspect translation behaviour\n",
    "            if idx > 0 and idx % 2000 == 0:\n",
    "                print(\"Loss: {}\".format(loss.item() / target_length))\n",
    "                print(\"Acc: {}\".format(acc_per_epoch / (idx + 1)))\n",
    "                print()\n",
    "                print(\"True action: {}\".format(true_sent))\n",
    "                print(\"Pred action: {}\".format(pred_sent))\n",
    "                print()\n",
    "                print(\"Target length: {}\".format(target_length))\n",
    "                print(\"True sent length: {}\".format(len(true_sent.split())))\n",
    "                print(\"Pred sent length: {}\".format(len(pred_sent.split())))\n",
    "                print()\n",
    "                \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            loss_per_epoch += loss.item() / target_length\n",
    "        \n",
    "        loss_per_epoch /= n_lang_pairs\n",
    "        acc_per_epoch /= n_lang_pairs\n",
    "        \n",
    "        print(\"Train loss: {}\".format(loss_per_epoch))\n",
    "        print(\"Train acc: {}\".format(acc_per_epoch))\n",
    "        print(\"Current teacher forcing ratio {}\".format(teacher_forcing_ratio))\n",
    "        \n",
    "        train_losses.append(loss_per_epoch)\n",
    "        train_accs.append(acc_per_epoch)\n",
    "        \n",
    "        teacher_forcing_ratio -= step_per_epoch # decrease teacher forcing ratio\n",
    "        \n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:01:41.793543Z",
     "start_time": "2019-11-27T14:01:41.790526Z"
    }
   },
   "outputs": [],
   "source": [
    "in_size = len(w2i_cmds)\n",
    "out_size = len(w2i_acts)\n",
    "emb_size = 15\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:01:44.504823Z",
     "start_time": "2019-11-27T14:01:44.499811Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:01:47.275070Z",
     "start_time": "2019-11-27T14:01:47.254127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(10, 15)\n",
       "  (lstm): LSTM(15, 50, num_layers=2, dropout=0.5)\n",
       "  (linear): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-27T14:01:43.647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(cmd_act_pairs, w2i_cmds, w2i_acts, i2w_acts, encoder, decoder, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
