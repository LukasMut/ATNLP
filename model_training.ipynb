{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:46:56.388901Z",
     "start_time": "2019-11-27T10:46:54.556532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from itertools import islice\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models.Encoder import *\n",
    "from models.Decoder import *\n",
    "from utils import *\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:46:56.832200Z",
     "start_time": "2019-11-27T10:46:56.828212Z"
    }
   },
   "outputs": [],
   "source": [
    "# define experiment\n",
    "exp='/exp_1a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:46:57.193235Z",
     "start_time": "2019-11-27T10:46:57.189247Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:46:57.680415Z",
     "start_time": "2019-11-27T10:46:57.530335Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset into memory, and get w2idx, idx2w, w2freq dictionaries and lists of input and output sentences\n",
    "cmd_vocab, w2i_cmds, i2w_cmds, cmds, act_vocab, w2i_acts, i2w_acts, acts = load_dataset(exp=exp, split='/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:46:58.590557Z",
     "start_time": "2019-11-27T10:46:58.585328Z"
    }
   },
   "outputs": [],
   "source": [
    "# create input and output language pairs\n",
    "cmd_act_pairs = create_pairs(cmds, acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:47:00.350599Z",
     "start_time": "2019-11-27T10:47:00.343631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['look', 'left', 'thrice', 'after', 'turn', 'opposite', 'left']\n",
      "Action: ['I_TURN_LEFT', 'I_TURN_LEFT', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK']\n"
     ]
    }
   ],
   "source": [
    "# show random command-action pair\n",
    "random_pair = random.choice(cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:47:02.123930Z",
     "start_time": "2019-11-27T10:47:02.116947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command sequence: tensor([12,  4,  6,  9, 15,  7,  4,  1])\n",
      "Action sequence: tensor([0, 4, 4, 4, 8, 4, 8, 4, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "cmd_act_pair = pairs2idx(random_pair, w2i_cmds, w2i_acts)\n",
    "print(\"Command sequence: {}\".format(cmd_act_pair[0]))\n",
    "print(\"Action sequence: {}\".format(cmd_act_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:15:46.913080Z",
     "start_time": "2019-11-27T11:15:46.893835Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(lang_pairs, w2i_source, w2i_target, i2w_target, encoder, decoder, \n",
    "          epochs:int=1, learning_rate:float=1e-4, teacher_forcing_decrease:float=0.05):\n",
    "        \n",
    "    train_losses, train_accs = [], []\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    training_pairs = [pairs2idx(random.choice(lang_pairs), w2i_cmds, w2i_acts) for _ in range(len(lang_pairs))]\n",
    "    max_target_length = max(iter(map(lambda lang_pair: len(lang_pair[1]), training_pairs)))\n",
    "    n_lang_pairs = len(training_pairs)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    teacher_forcing_ratio = 0.9\n",
    "    \n",
    "    for epoch in trange(epochs,  desc=\"Epoch\"):\n",
    "        \n",
    "        loss_per_epoch = 0\n",
    "        acc_per_epoch = 0\n",
    "        \n",
    "        for idx, train_pair in enumerate(training_pairs):\n",
    "            \n",
    "            loss = 0\n",
    "            \n",
    "            command = train_pair[0].to(device)\n",
    "            action = train_pair[1].to(device)\n",
    "\n",
    "            encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            input_length = command.size(0)\n",
    "            target_length = action.size(0)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(command, encoder_hidden)\n",
    "            \n",
    "            decoder_input = action[0] # SOS token\n",
    "            \n",
    "            # NOTE: line below is necessary since encoder_hidden.shape = n_layers*n_directions x hidden_size\n",
    "            decoder_hidden = encoder_hidden[-1] if encoder.n_layers > 1 else encoder_hidden\n",
    "\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            \n",
    "            pred_sent = \"\"\n",
    "            true_sent = ' '.join([i2w_target[act.item()] for act in islice(action, 1, None)]) # skip SOS token\n",
    "            \n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: feed target as the next input\n",
    "                for i in range(1, target_length): # range(1, max_target_length)\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0  # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    if i >= target_length:\n",
    "                        loss += criterion(decoder_out, torch.tensor(w2i_target['<EOS>'], dtype=torch.long).unsqueeze(0).to(device))\n",
    "                        decoder_input = pred.squeeze() # action[-2]\n",
    "                    else:\n",
    "                        loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                        decoder_input = action[i] # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if pred.squeeze().item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "                \n",
    "            else:\n",
    "                # Autoregression: feed previous prediction as the next input\n",
    "                for i in range(1, max_target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0 # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    if i >= target_length:\n",
    "                        loss += criterion(decoder_out, torch.tensor(w2i_target['<EOS>'], dtype=torch.long).unsqueeze(0).to(device))\n",
    "                    else:\n",
    "                        loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    \n",
    "                    decoder_input = pred.squeeze() # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if decoder_input.item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "\n",
    "            acc_per_epoch += 1 if (pred_sent == true_sent) else 0 # exact match accuracy\n",
    "        \n",
    "            loss.backward()\n",
    "            \n",
    "            # inspect translation behaviour\n",
    "            if idx > 0 and idx % 1000 == 0:\n",
    "                print(\"Loss: {}\".format(loss.item() / target_length))\n",
    "                print(\"Acc: {}\".format(acc_per_epoch / (idx + 1)))\n",
    "                print()\n",
    "                print(\"True action: {}\".format(true_sent))\n",
    "                print(\"Pred action: {}\".format(pred_sent))\n",
    "                print()\n",
    "                print(\"Target length: {}\".format(target_length))\n",
    "                print(\"True sent length: {}\".format(len(true_sent.split())))\n",
    "                print(\"Pred sent length: {}\".format(len(pred_sent.split())))\n",
    "                print()\n",
    "                \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            loss_per_epoch += loss.item() / target_length\n",
    "        \n",
    "        loss_per_epoch /= n_lang_pairs\n",
    "        acc_per_epoch /= n_lang_pairs\n",
    "        \n",
    "        print(\"Train loss: {}\".format(loss_per_epoch))\n",
    "        print(\"Train acc: {}\".format(acc_per_epoch))\n",
    "        \n",
    "        train_losses.append(loss_per_epoch)\n",
    "        train_accs.append(acc_per_epoch)\n",
    "        \n",
    "        # per epoch decrease teacher forcing ratio\n",
    "        teacher_forcing_ratio -= teacher_forcing_decrease\n",
    "        \n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:07:42.520978Z",
     "start_time": "2019-11-27T11:07:42.516989Z"
    }
   },
   "outputs": [],
   "source": [
    "in_size = len(w2i_cmds)\n",
    "out_size = len(w2i_acts)\n",
    "emb_size = 15\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:07:44.306064Z",
     "start_time": "2019-11-27T11:07:44.300052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:07:46.073740Z",
     "start_time": "2019-11-27T11:07:46.052796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(9, 15)\n",
       "  (lstm): LSTM(15, 200, dropout=0.5)\n",
       "  (linear): Linear(in_features=200, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:10:37.358689Z",
     "start_time": "2019-11-27T11:07:47.808296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8056693077087402\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_TURN_LEFT I_RUN I_JUMP I_JUMP <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT <EOS> \n",
      "\n",
      "Target length: 20\n",
      "True sent length: 19\n",
      "Pred sent length: 11\n",
      "\n",
      "Loss: 1.233809471130371\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_LEFT I_WALK I_TURN_LEFT I_TURN_LEFT I_RUN <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT <EOS> \n",
      "\n",
      "Target length: 8\n",
      "True sent length: 7\n",
      "Pred sent length: 8\n",
      "\n",
      "Loss: 0.47754757744925364\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_LEFT I_TURN_LEFT <EOS>\n",
      "Pred action: I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT <EOS> \n",
      "\n",
      "Target length: 28\n",
      "True sent length: 27\n",
      "Pred sent length: 11\n",
      "\n",
      "Loss: 0.7881346615878019\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_TURN_LEFT I_JUMP <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT <EOS> \n",
      "\n",
      "Target length: 11\n",
      "True sent length: 10\n",
      "Pred sent length: 10\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-229ce269256e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd_act_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2i_cmds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2i_acts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi2w_acts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-99797a21c173>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(lang_pairs, w2i_source, w2i_target, i2w_target, encoder, decoder, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0macc_per_epoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpred_sent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrue_sent\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# exact match accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m# Inspection of behaviour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(cmd_act_pairs, w2i_cmds, w2i_acts, i2w_acts, encoder, decoder, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
