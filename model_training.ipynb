{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.549944Z",
     "start_time": "2019-11-27T13:58:36.153305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from itertools import islice\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models.Encoder import *\n",
    "from models.Decoder import *\n",
    "from utils import *\n",
    "\n",
    "# set random seed to reproduce results\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.555026Z",
     "start_time": "2019-11-27T13:58:37.549944Z"
    }
   },
   "outputs": [],
   "source": [
    "# define experiment\n",
    "exp='/exp_1a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.565027Z",
     "start_time": "2019-11-27T13:58:37.557020Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.691707Z",
     "start_time": "2019-11-27T13:58:37.566030Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset into memory, and get w2idx, idx2w, w2freq dictionaries and lists of input and output sentences\n",
    "cmd_vocab, w2i_cmds, i2w_cmds, cmds, act_vocab, w2i_acts, i2w_acts, acts = load_dataset(exp=exp, split='/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.699639Z",
     "start_time": "2019-11-27T13:58:37.692657Z"
    }
   },
   "outputs": [],
   "source": [
    "# create input and output language pairs\n",
    "cmd_act_pairs = create_pairs(cmds, acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.706652Z",
     "start_time": "2019-11-27T13:58:37.700647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['look', 'left', 'thrice', 'after', 'turn', 'opposite', 'left']\n",
      "Action: ['I_TURN_LEFT', 'I_TURN_LEFT', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK']\n"
     ]
    }
   ],
   "source": [
    "# show random command-action pair\n",
    "random_pair = random.choice(cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.713621Z",
     "start_time": "2019-11-27T13:58:37.707618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command sequence: tensor([13,  5,  7, 10, 16,  8,  5,  2])\n",
      "Action sequence: tensor([1, 5, 5, 5, 9, 5, 9, 5, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "cmd_act_pair = pairs2idx(random_pair, w2i_cmds, w2i_acts)\n",
    "print(\"Command sequence: {}\".format(cmd_act_pair[0]))\n",
    "print(\"Action sequence: {}\".format(cmd_act_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:13.159985Z",
     "start_time": "2019-11-27T14:11:46.727Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(lang_pairs, w2i_source, w2i_target, i2w_target, encoder, decoder, epochs:int,\n",
    "          batch_size:int=1, learning_rate:float=1e-3, max_ratio:float=0.95, min_ratio:float=0.15):\n",
    "        \n",
    "    # each n_iters plot behaviour of RNN Decoder\n",
    "    n_iters = 3000\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    training_pairs = [pairs2idx(random.choice(lang_pairs), w2i_cmds, w2i_acts) for _ in range(len(lang_pairs))]\n",
    "    max_target_length = max(iter(map(lambda lang_pair: len(lang_pair[1]), training_pairs)))\n",
    "    n_lang_pairs = len(training_pairs)\n",
    "    \n",
    "    # negative log-likelihood loss\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # teacher forcing curriculum\n",
    "    # decrease teacher forcing ratio per epoch (start off with high ratio and move in equal steps to min_ratio)\n",
    "    ratio_diff = max_ratio-min_ratio\n",
    "    step_per_epoch = ratio_diff / epochs\n",
    "    teacher_forcing_ratio = max_ratio\n",
    "    \n",
    "    for epoch in trange(epochs,  desc=\"Epoch\"):\n",
    "                \n",
    "        loss_per_epoch = 0\n",
    "        acc_per_epoch = 0\n",
    "        \n",
    "        for idx, train_pair in enumerate(training_pairs):\n",
    "            \n",
    "            loss = 0\n",
    "            \n",
    "            command = train_pair[0].to(device)\n",
    "            action = train_pair[1].to(device)\n",
    "            \n",
    "            # initialise as many hidden states as there are sequences in the mini-batch (1 for the beginning)\n",
    "            encoder_hidden = encoder.init_hidden(batch_size)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            input_length = command.size(0)\n",
    "            target_length = action.size(0)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(command, encoder_hidden)\n",
    "            \n",
    "            decoder_input = action[0] # SOS token\n",
    "            \n",
    "            decoder_hidden = encoder_hidden # init decoder hidden with encoder hidden \n",
    "\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            \n",
    "            pred_sent = \"\"\n",
    "            true_sent = ' '.join([i2w_target[act.item()] for act in islice(action, 1, None)]).strip() # skip SOS token\n",
    "            \n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: feed target as the next input\n",
    "                for i in range(1, target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0  # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    decoder_input = action[i] # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if pred.squeeze().item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "            else:\n",
    "                # Autoregressive RNN: feed previous prediction as the next input\n",
    "                for i in range(1, max_target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0 # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    if i >= target_length:\n",
    "                        loss += criterion(decoder_out, torch.tensor(w2i_target['<EOS>'], dtype=torch.long).unsqueeze(0).to(device))\n",
    "                    else:\n",
    "                        loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    \n",
    "                    decoder_input = pred.squeeze() # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if decoder_input.item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "            \n",
    "            # strip off any leading or trailing white spaces\n",
    "            pred_sent = pred_sent.strip()\n",
    "            acc_per_epoch += 1 if pred_sent == true_sent else 0 # exact match accuracy\n",
    "        \n",
    "            loss.backward()\n",
    "            \n",
    "            # inspect translation behaviour\n",
    "            if idx > 0 and idx % n_iters == 0:\n",
    "                print(\"Loss: {}\".format(loss.item() / target_length)) # current per sequence loss\n",
    "                print(\"Acc: {}\".format(acc_per_epoch / (idx + 1))) # current per iters accuracy\n",
    "                print()\n",
    "                print(\"True action: {}\".format(true_sent))\n",
    "                print(\"Pred action: {}\".format(pred_sent))\n",
    "                print()\n",
    "                print(\"Target length: {}\".format(target_length))\n",
    "                print(\"True sent length: {}\".format(len(true_sent.split())))\n",
    "                print(\"Pred sent length: {}\".format(len(pred_sent.split())))\n",
    "                print()\n",
    "                \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            loss_per_epoch += loss.item() / target_length\n",
    "        \n",
    "        loss_per_epoch /= n_lang_pairs\n",
    "        acc_per_epoch /= n_lang_pairs\n",
    "        \n",
    "        print(\"Train loss: {}\".format(loss_per_epoch))\n",
    "        print(\"Train acc: {}\".format(acc_per_epoch))\n",
    "        print(\"Current teacher forcing ratio {}\".format(teacher_forcing_ratio))\n",
    "        \n",
    "        train_losses.append(loss_per_epoch)\n",
    "        train_accs.append(acc_per_epoch)\n",
    "        \n",
    "        teacher_forcing_ratio -= step_per_epoch # decrease teacher forcing ratio\n",
    "        \n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:23.551255Z",
     "start_time": "2019-11-27T14:45:23.546266Z"
    }
   },
   "outputs": [],
   "source": [
    "# source language (i.e., commands) vocabulary size |V_source|\n",
    "in_size = len(w2i_cmds)\n",
    "# target language (i.e., actions) vocabulary size |V_target|\n",
    "out_size = len(w2i_acts)\n",
    "# size of word embeddings\n",
    "emb_size = 15\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:26.240443Z",
     "start_time": "2019-11-27T14:45:26.234459Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:11:06.491474Z",
     "start_time": "2019-11-27T14:11:06.474495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(10, 15)\n",
       "  (lstm): LSTM(15, 50, num_layers=2, dropout=0.5)\n",
       "  (linear): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move models to GPU, if GPU is available (for faster computation)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:13.133056Z",
     "start_time": "2019-11-27T14:11:09.131473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|                                                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15120425820350647\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT \n",
      "\n",
      "Target length: 16\n",
      "True sent length: 15\n",
      "Pred sent length: 15\n",
      "\n",
      "Loss: 0.42156922817230225\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_RUN I_TURN_LEFT I_TURN_LEFT I_RUN <EOS>\n",
      "Pred action: I_RUN I_TURN_LEFT I_RUN I_RUN I_TURN_LEFT \n",
      "\n",
      "Target length: 6\n",
      "True sent length: 5\n",
      "Pred sent length: 5\n",
      "\n",
      "Loss: 0.36145031452178955\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_RIGHT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK <EOS> \n",
      "\n",
      "Target length: 16\n",
      "True sent length: 15\n",
      "Pred sent length: 13\n",
      "\n",
      "Train loss: 0.4863286133033926\n",
      "Train acc: 0.0\n",
      "Current teacher forcing ratio 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  20%|██████████████▌                                                          | 1/5 [17:05<1:08:22, 1025.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.053536683320999146\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT <EOS> \n",
      "\n",
      "Target length: 16\n",
      "True sent length: 15\n",
      "Pred sent length: 15\n",
      "\n",
      "Loss: 0.08276820182800293\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_RUN I_TURN_LEFT I_TURN_LEFT I_RUN <EOS>\n",
      "Pred action: I_RUN I_TURN_LEFT I_TURN_LEFT I_RUN <EOS> \n",
      "\n",
      "Target length: 6\n",
      "True sent length: 5\n",
      "Pred sent length: 5\n",
      "\n",
      "Loss: 0.7661991119384766\n",
      "Acc: 0.0\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_RIGHT I_LOOK I_TURN_RIGHT I_LOOK <EOS> \n",
      "\n",
      "Target length: 16\n",
      "True sent length: 15\n",
      "Pred sent length: 15\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-229ce269256e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd_act_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2i_cmds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2i_acts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi2w_acts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-a8abd8fe9c3e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(lang_pairs, w2i_source, w2i_target, i2w_target, encoder, decoder, epochs, batch_size, learning_rate, max_ratio, min_ratio)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0macc_per_epoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_sent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrue_sent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# exact match accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# inspect translation behaviour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(cmd_act_pairs, w2i_cmds, w2i_acts, i2w_acts, encoder, decoder, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
