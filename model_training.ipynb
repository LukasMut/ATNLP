{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.549944Z",
     "start_time": "2019-11-27T13:58:36.153305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from itertools import islice\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models.Encoder import *\n",
    "from models.Decoder import *\n",
    "from utils import *\n",
    "\n",
    "# set random seed to reproduce results\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.555026Z",
     "start_time": "2019-11-27T13:58:37.549944Z"
    }
   },
   "outputs": [],
   "source": [
    "# define experiment\n",
    "exp='/exp_1a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.565027Z",
     "start_time": "2019-11-27T13:58:37.557020Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.691707Z",
     "start_time": "2019-11-27T13:58:37.566030Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset into memory, and get w2idx, idx2w, w2freq dictionaries and lists of input and output sentences\n",
    "cmd_vocab, w2i_cmds, i2w_cmds, cmds, act_vocab, w2i_acts, i2w_acts, acts = load_dataset(exp=exp, split='/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.699639Z",
     "start_time": "2019-11-27T13:58:37.692657Z"
    }
   },
   "outputs": [],
   "source": [
    "# create input and output language pairs\n",
    "cmd_act_pairs = create_pairs(cmds, acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.706652Z",
     "start_time": "2019-11-27T13:58:37.700647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command: ['look', 'left', 'thrice', 'after', 'turn', 'opposite', 'left']\n",
      "Action: ['I_TURN_LEFT', 'I_TURN_LEFT', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK', 'I_TURN_LEFT', 'I_LOOK']\n"
     ]
    }
   ],
   "source": [
    "# show random command-action pair\n",
    "random_pair = random.choice(cmd_act_pairs)\n",
    "print(\"Command: {}\".format(random_pair[0]))\n",
    "print(\"Action: {}\".format(random_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:58:37.713621Z",
     "start_time": "2019-11-27T13:58:37.707618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command sequence: tensor([13,  5,  7, 10, 16,  8,  5,  2])\n",
      "Action sequence: tensor([1, 5, 5, 5, 9, 5, 9, 5, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "cmd_act_pair = pairs2idx(random_pair, w2i_cmds, w2i_acts)\n",
    "print(\"Command sequence: {}\".format(cmd_act_pair[0]))\n",
    "print(\"Action sequence: {}\".format(cmd_act_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:29.175135Z",
     "start_time": "2019-11-27T14:45:29.142328Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(lang_pairs, w2i_source, w2i_target, i2w_source, i2w_target, encoder, decoder, epochs:int, batch_size:int=1,\n",
    "          learning_rate:float=1e-3, max_ratio:float=0.95, min_ratio:float=0.15, detailed_analysis:bool=True):\n",
    "        \n",
    "    # each n_iters plot behaviour of RNN Decoder\n",
    "    n_iters = 3000\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    encoder_optimizer = Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    training_pairs = [pairs2idx(random.choice(lang_pairs), w2i_cmds, w2i_acts) for _ in range(len(lang_pairs))]\n",
    "    max_target_length = max(iter(map(lambda lang_pair: len(lang_pair[1]), training_pairs)))\n",
    "    n_lang_pairs = len(training_pairs)\n",
    "    \n",
    "    # negative log-likelihood loss\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # teacher forcing curriculum\n",
    "    # decrease teacher forcing ratio per epoch (start off with high ratio and move in equal steps to min_ratio)\n",
    "    ratio_diff = max_ratio-min_ratio\n",
    "    step_per_epoch = ratio_diff / epochs\n",
    "    teacher_forcing_ratio = max_ratio\n",
    "    \n",
    "    for epoch in trange(epochs,  desc=\"Epoch\"):\n",
    "                \n",
    "        loss_per_epoch = 0\n",
    "        acc_per_epoch = 0\n",
    "        \n",
    "        for idx, train_pair in enumerate(training_pairs):\n",
    "            \n",
    "            loss = 0\n",
    "            \n",
    "            command = train_pair[0].to(device)\n",
    "            action = train_pair[1].to(device)\n",
    "            \n",
    "            # initialise as many hidden states as there are sequences in the mini-batch (1 for the beginning)\n",
    "            encoder_hidden = encoder.init_hidden(batch_size)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            input_length = command.size(0)\n",
    "            target_length = action.size(0)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(command, encoder_hidden)\n",
    "            \n",
    "            decoder_input = action[0] # SOS token\n",
    "            \n",
    "            decoder_hidden = encoder_hidden # init decoder hidden with encoder hidden \n",
    "\n",
    "            use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "            \n",
    "            pred_sent = \"\"\n",
    "            true_sent = ' '.join([i2w_target[act.item()] for act in islice(action, 1, None)]).strip() # skip SOS token\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: feed target as the next input\n",
    "                for i in range(1, target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0  # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    decoder_input = action[i] # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if pred.squeeze().item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "            else:\n",
    "                # Autoregressive RNN: feed previous prediction as the next input\n",
    "                for i in range(1, max_target_length):\n",
    "                    decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    dim = 1 if len(decoder_out.shape) > 1 else 0 # crucial to correctly compute the argmax\n",
    "                    pred = torch.argmax(decoder_out, dim) # argmax computation\n",
    "                    \n",
    "                    if i >= target_length:\n",
    "                        loss += criterion(decoder_out, torch.tensor(w2i_target['<EOS>'], dtype=torch.long).unsqueeze(0).to(device))\n",
    "                    else:\n",
    "                        loss += criterion(decoder_out, action[i].unsqueeze(0))\n",
    "                    \n",
    "                    decoder_input = pred.squeeze() # convert list of int into int\n",
    "                    \n",
    "                    pred_sent += i2w_target[pred.item()] + \" \"\n",
    "                    \n",
    "                    if decoder_input.item() == w2i_target['<EOS>']:\n",
    "                        break\n",
    "            \n",
    "            # strip off any leading or trailing white spaces\n",
    "            pred_sent = pred_sent.strip()\n",
    "            acc_per_epoch += 1 if pred_sent == true_sent else 0 # exact match accuracy\n",
    "        \n",
    "            loss.backward()\n",
    "            \n",
    "            ### inspect translation behaviour ###\n",
    "            if detailed_analysis:\n",
    "                nl_command = ' '.join([i2w_source[cmd.item()] for cmd in command]).strip()\n",
    "                if idx > 0 and idx % n_iters == 0:\n",
    "                    print(\"Loss: {}\".format(loss.item() / target_length)) # current per sequence loss\n",
    "                    print(\"Acc: {}\".format(acc_per_epoch / (idx + 1))) # current per iters exact-match accuracy\n",
    "                    print()\n",
    "                    print(\"Command: {}\".format(nl_command))\n",
    "                    print(\"True action: {}\".format(true_sent))\n",
    "                    print(\"Pred action: {}\".format(pred_sent))\n",
    "                    print()\n",
    "                    print(\"Target length: {}\".format(target_length))\n",
    "                    print(\"True sent length: {}\".format(len(true_sent.split())))\n",
    "                    print(\"Pred sent length: {}\".format(len(pred_sent.split())))\n",
    "                    print()\n",
    "                \n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            loss_per_epoch += loss.item() / target_length\n",
    "        \n",
    "        loss_per_epoch /= n_lang_pairs\n",
    "        acc_per_epoch /= n_lang_pairs\n",
    "        \n",
    "        print(\"Train loss: {}\".format(loss_per_epoch)) # loss\n",
    "        print(\"Train acc: {}\".format(acc_per_epoch)) # exact-match accuracy\n",
    "        print(\"Current teacher forcing ratio {}\".format(teacher_forcing_ratio))\n",
    "        \n",
    "        train_losses.append(loss_per_epoch)\n",
    "        train_accs.append(acc_per_epoch)\n",
    "        \n",
    "        teacher_forcing_ratio -= step_per_epoch # decrease teacher forcing ratio\n",
    "        \n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:31.929763Z",
     "start_time": "2019-11-27T14:45:31.926772Z"
    }
   },
   "outputs": [],
   "source": [
    "# source language (i.e., commands) vocabulary size |V_source|\n",
    "in_size = len(w2i_cmds)\n",
    "# target language (i.e., actions) vocabulary size |V_target|\n",
    "out_size = len(w2i_acts)\n",
    "# size of word embeddings\n",
    "emb_size = 15\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:35.279251Z",
     "start_time": "2019-11-27T14:45:35.274266Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(in_size, emb_size, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(emb_size, hidden_size, out_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:45:38.160545Z",
     "start_time": "2019-11-27T14:45:38.139602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(10, 15)\n",
       "  (lstm): LSTM(15, 50, num_layers=2, dropout=0.5)\n",
       "  (linear): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move models to GPU, if GPU is available (for faster computation)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-27T14:45:30.025Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   0%|                                                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5072052365257627\n",
      "Acc: 0.003332222592469177\n",
      "\n",
      "True action: I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_TURN_RIGHT I_JUMP <EOS>\n",
      "Pred action: I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN <EOS>\n",
      "\n",
      "Target length: 21\n",
      "True sent length: 20\n",
      "Pred sent length: 19\n",
      "\n",
      "Loss: 0.6420160021100726\n",
      "Acc: 0.01016497250458257\n",
      "\n",
      "True action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_WALK <EOS>\n",
      "Pred action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK\n",
      "\n",
      "Target length: 7\n",
      "True sent length: 6\n",
      "Pred sent length: 6\n",
      "\n",
      "Loss: 0.747722053527832\n",
      "Acc: 0.023886234862793024\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_RIGHT I_JUMP <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_LEFT I_JUMP <EOS>\n",
      "\n",
      "Target length: 5\n",
      "True sent length: 4\n",
      "Pred sent length: 4\n",
      "\n",
      "Loss: 0.25725793838500977\n",
      "Acc: 0.04307974335472044\n",
      "\n",
      "True action: I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP <EOS>\n",
      "Pred action: I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP <EOS>\n",
      "\n",
      "Target length: 10\n",
      "True sent length: 9\n",
      "Pred sent length: 9\n",
      "\n",
      "Loss: 0.5500062874385289\n",
      "Acc: 0.07339510699286714\n",
      "\n",
      "True action: I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK <EOS>\n",
      "Pred action: I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT\n",
      "\n",
      "Target length: 14\n",
      "True sent length: 13\n",
      "Pred sent length: 13\n",
      "\n",
      "Train loss: 0.5144623005594375\n",
      "Train acc: 0.09122429459588713\n",
      "Current teacher forcing ratio 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:  20%|██████████████▌                                                          | 1/5 [17:16<1:09:04, 1036.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18827129545665922\n",
      "Acc: 0.28123958680439853\n",
      "\n",
      "True action: I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_TURN_RIGHT I_JUMP <EOS>\n",
      "Pred action: I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_JUMP <EOS>\n",
      "\n",
      "Target length: 21\n",
      "True sent length: 20\n",
      "Pred sent length: 20\n",
      "\n",
      "Loss: 0.17597307477678573\n",
      "Acc: 0.32544575904016\n",
      "\n",
      "True action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_WALK <EOS>\n",
      "Pred action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_WALK I_WALK\n",
      "\n",
      "Target length: 7\n",
      "True sent length: 6\n",
      "Pred sent length: 6\n",
      "\n",
      "Loss: 0.10747013092041016\n",
      "Acc: 0.36773691812020887\n",
      "\n",
      "True action: I_TURN_LEFT I_TURN_RIGHT I_JUMP <EOS>\n",
      "Pred action: I_TURN_LEFT I_TURN_RIGHT I_JUMP <EOS>\n",
      "\n",
      "Target length: 5\n",
      "True sent length: 4\n",
      "Pred sent length: 4\n",
      "\n",
      "Loss: 0.30910334587097166\n",
      "Acc: 0.4101324889592534\n",
      "\n",
      "True action: I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP <EOS>\n",
      "Pred action: I_TURN_LEFT I_LOOK I_TURN_LEFT I_LOOK I_TURN_LEFT I_JUMP I_JUMP <EOS>\n",
      "\n",
      "Target length: 10\n",
      "True sent length: 9\n",
      "Pred sent length: 8\n",
      "\n",
      "Loss: 0.1211449418749128\n",
      "Acc: 0.45316978868075464\n",
      "\n",
      "True action: I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK <EOS>\n",
      "Pred action: I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_LEFT I_JUMP I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT\n",
      "\n",
      "Target length: 14\n",
      "True sent length: 13\n",
      "Pred sent length: 13\n",
      "\n",
      "Train loss: 0.18086377509425744\n",
      "Train acc: 0.475011956001913\n",
      "Current teacher forcing ratio 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:  40%|██████████████████████████████                                             | 2/5 [33:50<51:11, 1023.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04883702596028646\n",
      "Acc: 0.6904365211596135\n",
      "\n",
      "True action: I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_TURN_RIGHT I_JUMP <EOS>\n",
      "Pred action: I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN I_TURN_RIGHT I_JUMP I_JUMP <EOS>\n",
      "\n",
      "Target length: 21\n",
      "True sent length: 20\n",
      "Pred sent length: 20\n",
      "\n",
      "Loss: 0.09396934509277344\n",
      "Acc: 0.7038826862189635\n",
      "\n",
      "True action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_WALK <EOS>\n",
      "Pred action: I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_WALK <EOS>\n",
      "\n",
      "Target length: 7\n",
      "True sent length: 6\n",
      "Pred sent length: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(cmd_act_pairs, w2i_cmds, w2i_acts, i2w_cmds, i2w_acts, encoder, decoder, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
